{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Analysis Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Normal or Abnormal Industrial Valves, Using Transfer Learning Technology upon Google's Pre-Trained Deep Neural Network\n",
    "\n",
    "The use case here is to use drone to provide regular surveillance on remote or dangerous areas, capturing image of industrial equipment like valves, them steam the image back for automatic malfunction diagnosis, using machine intelligence. This improves safety and efficiency compared to current human-involved processes, without large investment on wired sensor infrastructure. The core part of this solution involves advanced image analysis in real world.\n",
    "\n",
    "\n",
    "In this lab, you will carry out a transfer learning example based on Google Inception-v3 image recognition neural network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You will learn:\n",
    "* Explore images in customer’s industry.\n",
    "* Reposition a pre-trained deep neural net for new image recognition task.\n",
    "* Perform feature extraction.\n",
    "* Obtain deep feature representation of customer’s original image.\n",
    "* Train a simple machine learning model for new classification task.\n",
    "* Evaluate results of this transfer learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Explore images in customer’s industry.\n",
    "Let's have a look at the problem regarding real valve images, in 'images' directory:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Normal Valves:\n",
    "\n",
    "<img align=\"left\" src='images/normal_valve_41.jpg' width=20%>\n",
    "<img align=\"left\" src='images/normal_valve_07.jpg' width=20%>\n",
    "<img align=\"left\" src='images/normal_valve_05.jpg' width=20%>\n",
    "<img align=\"left\" src='images/normal_valve_02.jpg' width=20%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Abormal Valves:\n",
    "\n",
    "<img align=\"left\" src='images/abnormal_valve_09.jpg' width=20%>\n",
    "<img align=\"left\" src='images/abnormal_valve_49.jpg' width=20%>\n",
    "<img align=\"left\" src='images/abnormal_valve_18.jpg' width=20%>\n",
    "<img align=\"left\" src='images/abnormal_valve_20.jpg' width=20%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By: **Sam Gu** [ Data Science Trainer ]\n",
    "\n",
    "\n",
    "May 2017\n",
    "\n",
    "\n",
    "Credit: This python notebook was adapted based on: https://www.kernix.com/blog/image-classification-with-a-pre-trained-deep-neural-network_p11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Google's Inception-v3 Deep Neural Network Model\n",
    "\n",
    "The pre-trained deep learning model we shall use here is Inception-v3. It has been developed by Google and has been trained for the ImageNet Competition.\n",
    "\n",
    "<img align=\"left\" src='https://4.bp.blogspot.com/-TMOLlkJBxms/Vt3HQXpE2cI/AAAAAAAAA8E/7X7XRFOY6Xo/s1600/image03.png' width=90%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have downloaded this pre-trained Inception model at: 'reference/reusable_model/classify_image_graph_def.pb'. If you want to re-download this model, run: \n",
    "> !python reference/classify_image.py --model_dir reference/reusable_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reposition a pre-trained deep neural net for new image recognition task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.platform\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.contrib import learn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "from IPython.core.display import Image, display\n",
    "\n",
    "print('TensorFlow Verions: %s' % tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_dir = 'reference/reusable_model/'\n",
    "images_dir = 'images/'\n",
    "list_images = [images_dir+f for f in os.listdir(images_dir) if re.search('jpg|JPG', f)]\n",
    "print('Number of Customer\\'s Images       : %d' % len(list_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use TensorFlow, you should define a graph that represents the description of computations. Then these computations will be executed within what is called sessions. If you want to know more about the basics of TensorFlow, you can go to: https://www.tensorflow.org/\n",
    "\n",
    "The following function creates a graph from the graph definition that we just downloaded and that is saved in classify_image_graph_def.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_graph():\n",
    "  with gfile.FastGFile(os.path.join(model_dir, 'classify_image_graph_def.pb'), 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    _ = tf.import_graph_def(graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Perform feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to extract relevant **deep features**.\n",
    "\n",
    "To do so, we retrieve the **next-to-last** layer of the Inception-v3 as a feature vector for each image. The last layer of the convolutional neural network corresponds to the very specific ImageNet classification task, the categories that it will be output will not be useful to our valve image diagnosis.\n",
    "\n",
    "While the output of the next-to-last layer are more generic for image feature enrichment. These deep features are useful for **transfer learning** another classification task, so we extract the output of this layer. In TensorFlow, this layer is called **bottleneck pool_3**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src='reference/note_slide/note_slide_06.JPG' width=60%>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define following function to generate deep features corresponding to the output of **bottleneck** layer and the labels (**abnormal_valve** & **normal_valve** based on file name) for each customer image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(list_images):\n",
    "  nb_features = 2048\n",
    "  features = np.empty((len(list_images),nb_features)) # Deep Features to be stored here\n",
    "  labels = [] # Image class labels to be stored here\n",
    "\n",
    "  create_graph() # Create a TensorFlow computation graph\n",
    "  \n",
    "  with tf.Session() as sess:\n",
    "    next_to_last_tensor = sess.graph.get_tensor_by_name('pool_3:0') # We want the output features from this layer of Inception model\n",
    "    \n",
    "    for ind, image in enumerate(list_images):\n",
    "      if (ind%10 == 0):\n",
    "        print('Processing %s ...' % (image))\n",
    "      if not gfile.Exists(image):\n",
    "        tf.logging.fatal('File does not exist %s', image)\n",
    "          \n",
    "      image_data = gfile.FastGFile(image, 'rb').read()\n",
    "      predictions = sess.run(next_to_last_tensor,\n",
    "                             {'DecodeJpeg/contents:0': image_data})\n",
    "      features[ind,:] = np.squeeze(predictions) # Store the output deep features for images\n",
    "      labels.append(re.split('_\\d+',image.split('/')[1])[0]) # Get class label based on file names: Class + '_' + Digits + .jpg|JPG\n",
    "          \n",
    "    print('')\n",
    "    print('Processing Completed !')\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Obtain deep feature representation of customer’s original image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute deep feature generation for each valve image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features, labels = extract_features(list_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Number of Images Processed         : %d' % len(features))\n",
    "print('Unique Image Classes (Labels)      : %s' % list(set(labels)))\n",
    "print('Number of Deep Features per Images : %d <<<<<<<< Question here: Why 2048?' % len(features[0]))\n",
    "print('An Image\\'s Deep Features           : %s' % features[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For TensorFlow machine learning model, transform label to number: **'normal_valve' -> 0** & **'abnormal_valve' -> 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_number = []\n",
    "for i in range(len(labels)):\n",
    "  if labels[i] == 'abnormal_valve': labels_number.append(1)\n",
    "  else: labels_number.append(0)\n",
    "print(labels)\n",
    "print(labels_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the features and labels are saved, so they can be used without re-running above slow deep feature generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(features, open('reference/features', 'wb'))\n",
    "pickle.dump(labels_number, open('reference/labels_number', 'wb'))\n",
    "pickle.dump(labels, open('reference/labels', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train a simple machine learning model for new classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use the deep features that we just generated to train a new machine leaning classifier/model on the valve images. Another strategy could be to re-train the last layer of the deep neural net in TensorFlow: https://www.tensorflow.org/tutorials/image_retraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src='reference/note_slide/note_slide_07.JPG' width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Prepare training and test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features      = pickle.load(open('reference/features'))\n",
    "labels_number = pickle.load(open('reference/labels_number'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 We will use 75% of the data for training and 25% for testing/prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_features_train, image_features_test, image_label_train, image_label_test = cross_validation.train_test_split(\n",
    "  features, labels_number, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Classifying the images with a simple TensorFlow linear model:\n",
    "We now chose a simple TensorFlow model to diagnose valve images into binary classes using deep features as input.\n",
    "\n",
    "Machine learning model's pattern\n",
    "\n",
    "    estimator         : Choose a machine learning model to use. (Here we use: LinearClassifier)\n",
    "    estimator.fit     : Train the model iteratively.\n",
    "    estimator.predict : Use the trained model to retrieve predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_classes = len(set(image_label_train))\n",
    "estimator = learn.LinearClassifier(feature_columns = \n",
    "                        [tf.contrib.layers.real_valued_column(\"\", dimension=image_features_train.shape[1])], n_classes=n_classes)\n",
    "estimator.fit(image_features_train, image_label_train, steps=50)\n",
    "image_label_predicted = list(estimator.predict(image_features_test))\n",
    "print('')\n",
    "print('===================================================')\n",
    "print('TensorFlow machine learning completed successfully!')\n",
    "print('===================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Evaluate results of this transfer learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Evaluation of Model Performance using Accuracy Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy: {0:0.1f}%\".format(accuracy_score(image_label_test, image_label_predicted)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Evaluation of Model Performance using Confusion Matrix:\n",
    "\n",
    "<img style=\"float: left;\" width=\"50%\" src=\"https://i.ytimg.com/vi/AOIkPnKu0YA/maxresdefault.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate Confusion matrix\n",
    "cmlabels = list(set(labels_number)) # 0: Normal | 1: Abnormal\n",
    "cm = confusion_matrix(image_label_predicted, image_label_test, cmlabels)\n",
    "print('Confusion matrix of the classifier')\n",
    "print(cm)\n",
    "\n",
    "# Visualize Confusion matrix\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title(u'Confusion matrix of the classifier', fontsize=14)\n",
    "fig.colorbar(cax)\n",
    "# ax.set_xticklabels([''] + cmlabels)\n",
    "# ax.set_yticklabels([''] + cmlabels)\n",
    "ax.set_xticklabels([''] + ['Normal', 'Abnormal'])\n",
    "ax.set_yticklabels([''] + ['Normal', 'Abnormal'])\n",
    "plt.xlabel(u'Actual Class')\n",
    "plt.ylabel(u'Predicted Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Let's have a look at those valve images diagnosed incorrectly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a list containing bad predictions\n",
    "wrong_prediction_index_list = []\n",
    "for i in range(len(image_label_predicted)): \n",
    "  if image_label_predicted[i] != image_label_test[i]: wrong_prediction_index_list.append(i)\n",
    "wrong_image_index_list = []\n",
    "for j in range(len(wrong_prediction_index_list)): \n",
    "  for k in range(len(features)):\n",
    "    if np.array_equal(image_features_test[wrong_prediction_index_list[j]], features[k]): wrong_image_index_list.append(k)\n",
    "\n",
    "# Display image & acutal class below the image\n",
    "print('================================================================')\n",
    "print('Below are images incorrectly predicted, with their actual class:')\n",
    "print('================================================================')\n",
    "for m in range(len(wrong_image_index_list)): \n",
    "    display(Image(list_images[wrong_image_index_list[m]]), list_images[wrong_image_index_list[m]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***[Take Away Question] Is there ways to further improve the prediction accuracy? Yes there are! You can find more from ... advanced GCP courses.***\n",
    "\n",
    "<img align=\"left\" src='https://4.bp.blogspot.com/-TMOLlkJBxms/Vt3HQXpE2cI/AAAAAAAAA8E/7X7XRFOY6Xo/s1600/image03.png' width=90%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations! You are now equipped with practical skills to carry out deep leaning image analysis in real world!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You have learnt:\n",
    "\n",
    "* Deep Learning Basics for Image Analysis\n",
    "* Real World Image Analysis Needs\n",
    "* Idea of Transfer Learning\n",
    "* Architecture of Transfer Learning\n",
    "* Hands-on Datalab Workshop on GCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions & Answers session for lecture and lab workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
